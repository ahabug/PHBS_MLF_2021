{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82d1e6d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f92b4",
   "metadata": {},
   "source": [
    "# Identify the most important vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2925aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T02:35:40.951557Z",
     "start_time": "2021-11-09T02:35:40.935550Z"
    }
   },
   "source": [
    "A prerequisite for finding trading signal is to understand whether the data we extract contains topics/signals related to market, and more importantly, whether it contains information that we may trade.\n",
    "\n",
    "This requires us to examine and evaluate the various topics and vocabulary representing these topics in the data. The so-called: garbage in, garbage out.\n",
    "\n",
    "To explore various topics in the FOMC documents, we will use Gensim’sLatent Dirichlet Allocation(Hidden Dirichlet distribution model). LDA is a generation probability model suitable for discrete data sets such as text. The function of LDA is as a hierarchical Bayesian model, in which each item in the collection is modeled as a finite mixture on the basic theme collection. In turn, each topic is shaped into an infinite mixture of basic topic probabilities.\n",
    "\n",
    "In LDA model, we need to estimate the number of topics in the dataset through the num_topics hyperparameter. According to models' coherence scores, 10 and 7 are wise choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, stop_words=all_stopwords):\n",
    "    \"\"\"\n",
    "    Tokenize and Lemmatize raw tweets in a given DataFrame.\n",
    "    Args:\n",
    "      stop_words: A list of Strings containing stop words to be removed.\n",
    "    Returns:\n",
    "      processed_tweets: A list of preprocessed tokens of type String.\n",
    "    \"\"\"\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = []\n",
    "    for w in word_tokenize(text):\n",
    "        if w not in stop_words:\n",
    "            words.append(w)\n",
    "    res = []\n",
    "    for w in words:\n",
    "        if len(w) > 2:\n",
    "            res.append(lemmatizer.lemmatize(w))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize & normalise statements and minutes\n",
    "pool = Pool(16)\n",
    "statements_list = df_statements[\"statements\"].to_list()\n",
    "statements_preprocessed = list(\n",
    "    tqdm(pool.imap(preprocess_text, statements_list), total=len(statements_list), desc='Multiprocess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_list = df_minutes[\"minutes\"].to_list()\n",
    "minutes_preprocessed = list(\n",
    "    tqdm(pool.imap(preprocess_text, minutes_list), total=len(minutes_list), desc='Multiprocess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbda330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2984f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_dict = gs.corpora.Dictionary(statements_preprocessed)\n",
    "minutes_dict = gs.corpora.Dictionary(minutes_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_statements = [statements_dict.doc2bow(doc) for doc in statements_preprocessed]\n",
    "cbow_minutes = [minutes_dict.doc2bow(doc) for doc in minutes_preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statements = gs.models.LdaMulticore(cbow_statements, num_topics=16, id2word=statements_dict, passes=10, workers=16)\n",
    "# model_statements.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06699924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_minutes = gs.models.LdaMulticore(cbow_minutes, num_topics=12, id2word=minutes_dict, passes=10, workers=16)\n",
    "model_minutes.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd03450",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vis_statements = gensimvis.prepare(model_statements, cbow_statements, statements_dict)\n",
    "pyLDAvis.display(topic_vis_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vis_minutes = gensimvis.prepare(model_minutes, cbow_minutes, minutes_dict)\n",
    "pyLDAvis.display(topic_vis_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(topic_vis_statements, 'topic_vis_statements.html')\n",
    "pyLDAvis.save_html(topic_vis_minutes, 'topic_vis_minutes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3549e",
   "metadata": {},
   "source": [
    "By examining the final topic map, we can see that the performance of the LDA model on capturing the salient topics and their constituent words in the data is not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71843799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_statements = gs.models.CoherenceModel(model=model_statements, texts=statements_preprocessed,\n",
    "                                                      dictionary=statements_dict, coherence='c_v')\n",
    "coherence_score_statements = coherence_model_statements.get_coherence()\n",
    "print(f'Coherence Score_Statements: {coherence_score_statements}')\n",
    "coherence_model_minutes = gs.models.CoherenceModel(model=model_minutes, texts=minutes_preprocessed,\n",
    "                                                   dictionary=minutes_dict, coherence='c_v')\n",
    "coherence_score_minutes = coherence_model_minutes.get_coherence()\n",
    "print(f'Coherence Score_Minutes: {coherence_score_minutes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26782c11",
   "metadata": {},
   "source": [
    "The results of Roder, Both and Hindeburg in the paper motivated us to choose the method of score measurement, which can be seen from the signature of the above consistency model logic. You can see that we have chosen the coherence ='c_v metric for the model, instead of'u_mass','c_v', and'c_uci'. We found that the \"c_v\" scoring standard can achieve better results than other methods, especially when the word set is small, which is in line with our choice. The consensus score of our model is X. We believe our model can be better if we have data with higher quality. Generally, our LDA model has been trained on the correct number of topics and maintains a sufficient degree of semantic similarity between words with higher scores in each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d964c0d",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a7dca",
   "metadata": {},
   "source": [
    "1. Kusner, M., Sun, Y., Kolkin, N., & Weinberger, K. (2015, June). From word embeddings to document distances. In International conference on machine learning (pp. 957-966). PMLR.\n",
    "2. Loughran, T., & McDonald, B. (2020). Measuring firm complexity. Available at SSRN 3645372.\n",
    "3. Röder, M., Both, A., & Hinneburg, A. (2015, February). Exploring the space of topic coherence measures. In Proceedings of the eighth ACM international conference on Web search and data mining (pp. 399-408).\n",
    "4. Sievert, C., & Shirley, K. (2014, June). LDAvis: A method for visualizing and interpreting topics. In Proceedings of the workshop on interactive language learning, visualization, and interfaces (pp. 63-70)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c3628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f101dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea10f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
